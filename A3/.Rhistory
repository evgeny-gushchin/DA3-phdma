X1 <- c("sales_mil_log", "sales_mil_log_sq", "d1_ln_fat_mod", "profit_loss_year_pl", "ind2_cat")
X2 <- c("sales_mil_log", "sales_mil_log_sq", "d1_ln_fat_mod", "profit_loss_year_pl", "fixed_assets_bs","share_eq_bs","curr_liab_bs ",   "curr_liab_bs_flag_high ", "curr_liab_bs_flag_error",  "age","foreign_management" , "ind2_cat")
X3 <- c("sales_mil_log", "sales_mil_log_sq", firm, engvar,                   d1)
X4 <- c("sales_mil_log", "sales_mil_log_sq", firm, engvar, engvar2, engvar3, d1, hr, qualityvars)
X5 <- c("sales_mil_log", "sales_mil_log_sq", firm, engvar, engvar2, engvar3, d1, hr, qualityvars, interactions1, interactions2)
# for LASSO
logitvars <- c("sales_mil_log", "sales_mil_log_sq", engvar, engvar2, engvar3, d1, hr, firm, qualityvars, interactions1, interactions2)
# for RF (no interactions, no modified features)
rfvars  <-  c("sales_mil", "d1_ln_fat", rawvars, hr, firm, qualityvars)
# Check simplest model X1
ols_modelx1 <- lm(formula(paste0("future_fast_growth ~", paste0(X1, collapse = " + "))),
data = data)
summary(ols_modelx1)
glm_modelx1 <- glm(formula(paste0("future_fast_growth ~", paste0(X1, collapse = " + "))),
data = data, family = "binomial")
summary(glm_modelx1)
# Check model X2
glm_modelx2 <- glm(formula(paste0("future_fast_growth ~", paste0(X2, collapse = " + "))),
data = data, family = "binomial")
summary(glm_modelx2)
#calculate average marginal effects (dy/dx) for logit
mx2 <- margins(glm_modelx2)
sum_table <- summary(glm_modelx2) %>%
coef() %>%
as.data.frame() %>%
select(Estimate) %>%
mutate(factor = row.names(.)) %>%
merge(summary(mx2)[,c("factor","AME")])
kable(x = sum_table, format = "latex", digits = 3,
col.names = c("Variable", "Coefficient", "dx/dy"),
caption = "Average Marginal Effects (dy/dx) for Logit Model") %>%
cat(.,file= "AME_logit_X2.tex")
ols_model <- lm(formula(paste0("future_fast_growth ~", paste0(X4, collapse = " + "))),
data = data)
summary(ols_model)
glm_model <- glm(formula(paste0("future_fast_growth ~", paste0(X4, collapse = " + "))),
data = data, family = "binomial")
summary(glm_model)
m <- margins(glm_model, vce = "none")
sum_table2 <- summary(glm_model) %>%
coef() %>%
as.data.frame() %>%
select(Estimate, `Std. Error`) %>%
mutate(factor = row.names(.)) %>%
merge(summary(m)[,c("factor","AME")])
kable(x = sum_table2, format = "latex", digits = 3,
col.names = c("Variable", "Coefficient", "SE", "dx/dy"),
caption = "Average Marginal Effects (dy/dx) for Logit Model") %>%
cat(.,file= "AME_logit_X4.tex")
set.seed(13505)
train_indices <- as.integer(createDataPartition(data$future_fast_growth, p = 0.8, list = FALSE))
data_train <- data[train_indices, ]
data_holdout <- data[-train_indices, ]
dim(data_train)
dim(data_holdout)
table(data$future_fast_growth_f)
table(data_train$future_fast_growth_f)
table(data_holdout$future_fast_growth_f)
twoClassSummaryExtended <- function (data, lev = NULL, model = NULL)
{
lvls <- levels(data$obs)
rmse <- sqrt(mean((data[, lvls[1]] - ifelse(data$obs == lev[2], 0, 1))^2))
c(defaultSummary(data, lev, model), "RMSE" = rmse)
}
# 5 fold cross-validation
train_control <- trainControl(
method = "cv",
number = 5,
classProbs = TRUE,
summaryFunction = twoClassSummaryExtended,
savePredictions = TRUE
)
logit_model_vars <- list("X1" = X1, "X2" = X2, "X3" = X3, "X4" = X4, "X5" = X5)
CV_RMSE_folds <- list()
logit_models <- list()
for (model_name in names(logit_model_vars)) {
features <- logit_model_vars[[model_name]]
set.seed(13505)
glm_model <- train(
formula(paste0("future_fast_growth_f ~", paste0(features, collapse = " + "))),
method = "glm",
data = data_train,
family = binomial,
trControl = train_control
)
logit_models[[model_name]] <- glm_model
# Calculate RMSE on test for each fold
CV_RMSE_folds[[model_name]] <- glm_model$resample[,c("Resample", "RMSE")]
}
lambda <- 10^seq(-1, -4, length = 10)
grid <- expand.grid("alpha" = 1, lambda = lambda)
set.seed(13505)
system.time({
logit_lasso_model <- train(
formula(paste0("future_fast_growth_f ~", paste0(logitvars, collapse = " + "))),
data = data_train,
method = "glmnet",
preProcess = c("center", "scale"),
family = "binomial",
trControl = train_control,
tuneGrid = grid,
na.action=na.exclude
)
})
tuned_logit_lasso_model <- logit_lasso_model$finalModel
best_lambda <- logit_lasso_model$bestTune$lambda
logit_models[["LASSO"]] <- logit_lasso_model
lasso_coeffs <- as.matrix(coef(tuned_logit_lasso_model, best_lambda))
write.csv(lasso_coeffs, "lasso_logit_coeffs.csv")
CV_RMSE_folds[["LASSO"]] <- logit_lasso_model$resample[,c("Resample", "RMSE")]
# Draw ROC Curve and calculate AUC for each folds --------------------------------
CV_AUC_folds <- list()
for (model_name in names(logit_models)) {
auc <- list()
model <- logit_models[[model_name]]
for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
cv_fold <-
model$pred %>%
filter(Resample == fold)
roc_obj <- roc(cv_fold$obs, cv_fold$fast_growth)
auc[[fold]] <- as.numeric(roc_obj$auc)
}
CV_AUC_folds[[model_name]] <- data.frame("Resample" = names(auc),
"AUC" = unlist(auc))
}
CV_RMSE <- list()
CV_AUC <- list()
for (model_name in names(logit_models)) {
CV_RMSE[[model_name]] <- mean(CV_RMSE_folds[[model_name]]$RMSE)
CV_AUC[[model_name]] <- mean(CV_AUC_folds[[model_name]]$AUC)
}
nvars <- lapply(logit_models, FUN = function(x) length(x$coefnames))
nvars[["LASSO"]] <- sum(lasso_coeffs != 0)
logit_summary1 <- data.frame("Number of predictors" = unlist(nvars),
"CV RMSE" = unlist(CV_RMSE),
"CV AUC" = unlist(CV_AUC))
kable(x = logit_summary1, format = "latex", booktabs=TRUE,  digits = 3, row.names = TRUE,
linesep = "", col.names = c("Number of predictors","CV RMSE","CV AUC")) %>%
cat(.,file= "logit_summary1.tex")
best_logit_no_loss <- logit_models[["X2"]]
logit_predicted_probabilities_holdout <- predict(best_logit_no_loss, newdata = data_holdout, type = "prob")
data_holdout[,"best_logit_no_loss_pred"] <- logit_predicted_probabilities_holdout[,"fast_growth"]
RMSE(data_holdout[, "best_logit_no_loss_pred", drop=TRUE], data_holdout$future_fast_growth)
# discrete ROC (with thresholds in steps) on holdout -------------------------------------------------
thresholds <- seq(0.05, 0.75, by = 0.05)
cm <- list()
true_positive_rates <- c()
false_positive_rates <- c()
for (thr in thresholds) {
holdout_prediction <- ifelse(data_holdout[,"best_logit_no_loss_pred"] < thr, "no_fast_growth", "fast_growth") %>%
factor(levels = c("no_fast_growth", "fast_growth"))
cm_thr <- confusionMatrix(holdout_prediction,data_holdout$future_fast_growth_f)$table
cm[[as.character(thr)]] <- cm_thr
true_positive_rates <- c(true_positive_rates, cm_thr["fast_growth", "fast_growth"] /
(cm_thr["fast_growth", "fast_growth"] + cm_thr["no_fast_growth", "fast_growth"]))
false_positive_rates <- c(false_positive_rates, cm_thr["fast_growth", "no_fast_growth"] /
(cm_thr["fast_growth", "no_fast_growth"] + cm_thr["no_fast_growth", "no_fast_growth"]))
}
tpr_fpr_for_thresholds <- tibble(
"threshold" = thresholds,
"true_positive_rate" = true_positive_rates,
"false_positive_rate" = false_positive_rates
)
#install.packages("viridis")
library(viridis)
discrete_roc_plot <- ggplot(
data = tpr_fpr_for_thresholds,
aes(x = false_positive_rate, y = true_positive_rate, color = threshold)) +
labs(x = "False positive rate (1 - Specificity)", y = "True positive rate (Sensitivity)") +
geom_point(size=2, alpha=0.8) +
scale_color_viridis(option = "D", direction = -1) +
scale_x_continuous(expand = c(0.01,0.01), limit=c(0,1), breaks = seq(0,1,0.1)) +
scale_y_continuous(expand = c(0.01,0.01), limit=c(0,1), breaks = seq(0,1,0.1)) +
theme_minimal() +
theme(legend.position ="right") +
theme(legend.title = element_text(size = 4),
legend.text = element_text(size = 4),
legend.key.size = unit(.4, "cm"))
discrete_roc_plot
save_fig("roc-discrete-holdout")
ggsave("roc-discrete-holdout.png", discrete_roc_plot, width = 8, height = 6, dpi = 300)
roc_obj_holdout <- roc(data_holdout$future_fast_growth, data_holdout$best_logit_no_loss_pred)
createRocPlot <- function(r, file_name,  myheight_small = 5.625, mywidth_small = 7.5) {
all_coords <- coords(r, x="all", ret="all", transpose = FALSE)
roc_plot <- ggplot(data = all_coords, aes(x = fpr, y = tpr)) +
geom_line(color="red", size = 0.7) +
geom_area(aes(fill = "green", alpha=0.4), alpha = 0.3, position = 'identity', color = "red") +
scale_fill_viridis(discrete = TRUE, begin=0.6, alpha=0.5, guide = FALSE) +
xlab("False Positive Rate (1-Specifity)") +
ylab("True Positive Rate (Sensitivity)") +
geom_abline(intercept = 0, slope = 1,  linetype = "dotted", col = "black") +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, .1), expand = c(0, 0.01)) +
scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, .1), expand = c(0.01, 0)) +
theme_minimal()
#+    theme(axis.text.x = element_text(size=13), axis.text.y = element_text(size=13),
#        axis.title.x = element_text(size=13), axis.title.y = element_text(size=13))
#save_fig(file_name, "small")
#ggsave(plot = roc_plot, paste0(file_name, ".png"),      width=mywidth_small, height=myheight_small, dpi=1200)
#cairo_ps(filename = paste0(file_name, ".eps"),    #        width = mywidth_small, height = myheight_small, pointsize = 12,    #       fallback_resolution = 1200)
#print(roc_plot)
#dev.off()
roc_plot
}
createRocPlot(roc_obj_holdout, "best_logit_no_loss_roc_plot_holdout")
ggsave("roc_plot.png", roc_plot, width = 8, height = 6, dpi = 300)
ggsave("roc_plot.png", createRocPlot(roc_obj_holdout, "best_logit_no_loss_roc_plot_holdout"), width = 8, height = 6, dpi = 300)
# default: the threshold 0.5 is used to convert probabilities to binary classes
logit_class_prediction <- predict(best_logit_no_loss, newdata = data_holdout)
summary(logit_class_prediction)
# confusion matrix: summarize different type of errors and successfully predicted cases
# positive = "yes": explicitly specify the positive case
cm_object1 <- confusionMatrix(logit_class_prediction, data_holdout$future_fast_growth_f, positive = "fast_growth")
cm1 <- cm_object1$table
cm1
# 0.5 same as before
holdout_prediction <-
ifelse(data_holdout$best_logit_no_loss_pred < 0.5, "no_fast_growth", "fast_growth") %>%
factor(levels = c("no_fast_growth", "fast_growth"))
cm_object1b <- confusionMatrix(holdout_prediction,data_holdout$future_fast_growth_f)
cm1b <- cm_object1b$table
cm1b
# a sensible choice: mean of predicted probabilities
mean_predicted_fast_growth_prob <- mean(data_holdout$best_logit_no_loss_pred)
mean_predicted_fast_growth_prob
holdout_prediction <-
ifelse(data_holdout$best_logit_no_loss_pred < mean_predicted_fast_growth_prob, "no_fast_growth", "fast_growth") %>%
factor(levels = c("no_fast_growth", "fast_growth"))
cm_object2 <- confusionMatrix(holdout_prediction,data_holdout$future_fast_growth_f)
cm2 <- cm_object2$table
cm2
# Introduce loss function
# relative cost of of a false negative classification (as compared with a false positive classification)
FP=1000
FN=5000
cost = FN/FP
# the prevalence, or the proportion of cases in the population (n.cases/(n.controls+n.cases))
prevelance = sum(data_train$future_fast_growth)/length(data_train$future_fast_growth)
best_tresholds <- list()
expected_loss <- list()
logit_cv_rocs <- list()
logit_cv_threshold <- list()
logit_cv_expected_loss <- list()
for (model_name in names(logit_models)) {
model <- logit_models[[model_name]]
colname <- paste0(model_name,"_prediction")
best_tresholds_cv <- list()
expected_loss_cv <- list()
for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
cv_fold <-
model$pred %>%
filter(Resample == fold)
roc_obj <- roc(cv_fold$obs, cv_fold$fast_growth)
best_treshold <- coords(roc_obj, "best", ret="all", transpose = FALSE,
best.method="youden", best.weights=c(cost, prevelance))
best_tresholds_cv[[fold]] <- best_treshold$threshold
expected_loss_cv[[fold]] <- (best_treshold$fp*FP + best_treshold$fn*FN)/length(cv_fold$fast_growth)
}
# average
best_tresholds[[model_name]] <- mean(unlist(best_tresholds_cv))
expected_loss[[model_name]] <- mean(unlist(expected_loss_cv))
# for fold #5
logit_cv_rocs[[model_name]] <- roc_obj
logit_cv_threshold[[model_name]] <- best_treshold
logit_cv_expected_loss[[model_name]] <- expected_loss_cv[[fold]]
}
logit_summary2 <- data.frame("Avg of optimal thresholds" = unlist(best_tresholds),
"Threshold for Fold5" = sapply(logit_cv_threshold, function(x) {x$threshold}),
"Avg expected loss" = unlist(expected_loss),
"Expected loss for Fold5" = unlist(logit_cv_expected_loss))
kable(x = logit_summary2, format = "latex", booktabs=TRUE,  digits = 3, row.names = TRUE,
linesep = "", col.names = c("Avg of optimal thresholds","Threshold for fold #5",
"Avg expected loss","Expected loss for fold #5")) %>%
cat(.,file= "logit_summary1.tex")
for (model_name in names(logit_cv_rocs)) {
r <- logit_cv_rocs[[model_name]]
best_coords <- logit_cv_threshold[[model_name]]
createLossPlot(r, best_coords,
paste0(model_name, "_loss_plot"))
createRocPlotWithOptimal(r, best_coords,
paste0(model_name, "_roc_plot"))
}
best_logit_with_loss <- logit_models[["X2"]]
best_logit_optimal_treshold <- best_tresholds[["X2"]]
logit_predicted_probabilities_holdout <- predict(best_logit_with_loss, newdata = data_holdout, type = "prob")
data_holdout[,"best_logit_with_loss_pred"] <- logit_predicted_probabilities_holdout[,"fast_growth"]
# ROC curve on holdout
roc_obj_holdout <- roc(data_holdout$future_fast_growth, data_holdout[, "best_logit_with_loss_pred", drop=TRUE])
# Get expected loss on holdout
holdout_treshold <- coords(roc_obj_holdout, x = best_logit_optimal_treshold, input= "threshold",
ret="all", transpose = FALSE)
expected_loss_holdout <- (holdout_treshold$fp*FP + holdout_treshold$fn*FN)/length(data_holdout$future_fast_growth)
expected_loss_holdout
# Confusion table on holdout with optimal threshold
holdout_prediction <-
ifelse(data_holdout$best_logit_with_loss_pred < best_logit_optimal_treshold, "no_fast_growth", "fast_growth") %>%
factor(levels = c("no_fast_growth", "fast_growth"))
cm_object3 <- confusionMatrix(holdout_prediction,data_holdout$future_fast_growth_f)
cm3 <- cm_object3$table
cm3
data_for_graph <- data_train
levels(data_for_graph$future_fast_growth_f) <- list("stay" = "no_fast_growth", "exit" = "fast_growth")
set.seed(13505)
rf_for_graph <-
rpart(
formula = future_fast_growth_f ~ sales_mil + profit_loss_year+ foreign_management,
data = data_for_graph,
control = rpart.control(cp = 0.0028, minbucket = 100)
)
rpart.plot(rf_for_graph, tweak=1, digits=2, extra=107, under = TRUE)
train_control <- trainControl(
method = "cv",
n = 5,
classProbs = TRUE, # same as probability = TRUE in ranger
summaryFunction = twoClassSummaryExtended,
savePredictions = TRUE
)
train_control$verboseIter <- TRUE
tune_grid <- expand.grid(
.mtry = c(5, 6, 7),
.splitrule = "gini",
.min.node.size = c(10, 15)
)
# getModelInfo("ranger")
set.seed(13505)
rf_model_p <- train(
formula(paste0("future_fast_growth_f ~ ", paste0(rfvars , collapse = " + "))),
method = "ranger",
data = data_train,
tuneGrid = tune_grid,
trControl = train_control
)
rf_model_p$results
best_mtry <- rf_model_p$bestTune$mtry
best_min_node_size <- rf_model_p$bestTune$min.node.size
# Get average (ie over the folds) RMSE and AUC ------------------------------------
CV_RMSE_folds[["rf_p"]] <- rf_model_p$resample[,c("Resample", "RMSE")]
auc <- list()
for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
cv_fold <-
rf_model_p$pred %>%
filter(Resample == fold)
roc_obj <- roc(cv_fold$obs, cv_fold$fast_growth)
auc[[fold]] <- as.numeric(roc_obj$auc)
}
CV_AUC_folds[["rf_p"]] <- data.frame("Resample" = names(auc),
"AUC" = unlist(auc))
CV_RMSE[["rf_p"]] <- mean(CV_RMSE_folds[["rf_p"]]$RMSE)
CV_AUC[["rf_p"]] <- mean(CV_AUC_folds[["rf_p"]]$AUC)
# Now use loss function and search for best thresholds and expected loss over folds -----
best_tresholds_cv <- list()
expected_loss_cv <- list()
for (fold in c("Fold1", "Fold2", "Fold3", "Fold4", "Fold5")) {
cv_fold <-
rf_model_p$pred %>%
filter(mtry == best_mtry,
min.node.size == best_min_node_size,
Resample == fold)
roc_obj <- roc(cv_fold$obs, cv_fold$fast_growth)
best_treshold <- coords(roc_obj, "best", ret="all", transpose = FALSE,
best.method="youden", best.weights=c(cost, prevelance))
best_tresholds_cv[[fold]] <- best_treshold$threshold
expected_loss_cv[[fold]] <- (best_treshold$fp*FP + best_treshold$fn*FN)/length(cv_fold$fast_growth)
}
# average
best_tresholds[["rf_p"]] <- mean(unlist(best_tresholds_cv))
expected_loss[["rf_p"]] <- mean(unlist(expected_loss_cv))
rf_summary <- data.frame("CV RMSE" = CV_RMSE[["rf_p"]],
"CV AUC" = CV_AUC[["rf_p"]],
"Avg of optimal thresholds" = best_tresholds[["rf_p"]],
"Threshold for Fold5" = best_treshold$threshold,
"Avg expected loss" = expected_loss[["rf_p"]],
"Expected loss for Fold5" = expected_loss_cv[[fold]])
kable(x = rf_summary, format = "latex", booktabs=TRUE,  digits = 3, row.names = TRUE,
linesep = "", col.names = c("CV RMSE", "CV AUC",
"Avg of optimal thresholds","Threshold for fold #5",
"Avg expected loss","Expected loss for fold #5")) %>%
cat(.,"rf_summary.tex")
rf_predicted_probabilities_holdout <- predict(rf_model_p, newdata = data_holdout, type = "prob")
data_holdout$rf_p_prediction <- rf_predicted_probabilities_holdout[,"fast_growth"]
RMSE(data_holdout$rf_p_prediction, data_holdout$future_fast_growth)
# ROC curve on holdout
roc_obj_holdout <- roc(data_holdout$future_fast_growth, data_holdout[, "rf_p_prediction", drop=TRUE])
# AUC
as.numeric(roc_obj_holdout$auc)
# Get expected loss on holdout with optimal threshold
holdout_treshold <- coords(roc_obj_holdout, x = best_tresholds[["rf_p"]] , input= "threshold",
ret="all", transpose = FALSE)
expected_loss_holdout <- (holdout_treshold$fp*FP + holdout_treshold$fn*FN)/length(data_holdout$future_fast_growth)
expected_loss_holdout
train_control <- trainControl(
method = "cv",
n = 5
)
train_control$verboseIter <- TRUE
set.seed(13505)
rf_model_f <- train(
formula(paste0("future_fast_growth_f ~ ", paste0(rfvars , collapse = " + "))),
method = "ranger",
data = data_train,
tuneGrid = tune_grid,
trControl = train_control
)
data_train$rf_f_prediction_class <-  predict(rf_model_f,type = "raw")
data_holdout$rf_f_prediction_class <- predict(rf_model_f, newdata = data_holdout, type = "raw")
#We use predicted classes to calculate expected loss based on our loss fn
fp <- sum(data_holdout$rf_f_prediction_class == "fast_growth" & data_holdout$future_fast_growth_f == "no_fast_growth")
fn <- sum(data_holdout$rf_f_prediction_class == "no_fast_growth" & data_holdout$future_fast_growth_f == "fast_growth")
(fp*FP + fn*FN)/length(data_holdout$future_fast_growth)
nvars[["rf_p"]] <- length(rfvars)
summary_results <- data.frame("Number of predictors" = unlist(nvars),
"CV RMSE" = unlist(CV_RMSE),
"CV AUC" = unlist(CV_AUC),
"CV threshold" = unlist(best_tresholds),
"CV expected Loss" = unlist(expected_loss))
model_names <- c("Logit X2",
"Logit LASSO","RF probability")
summary_results <- summary_results %>%
filter(rownames(.) %in% c("X2", "LASSO", "rf_p"))
rownames(summary_results) <- model_names
kable(x = summary_results, format = "latex", booktabs=TRUE,  digits = 3, row.names = TRUE,
linesep = "", col.names = c("Number of predictors", "CV RMSE", "CV AUC",
"CV threshold", "CV expected Loss")) %>%
cat(.,file= "summary_results.tex")
cm3
fp
fn
data_holdout$future_fast_growth_f
holdout_prediction
data_holdout$rf_f_prediction_class
cm_object4 <- confusionMatrix(data_holdout$rf_f_prediction_class,data_holdout$future_fast_growth_f)
cm4 <- cm_object4$table
cm4
kable(x = cm4, format = "latex", booktabs=TRUE,  digits = 0, row.names = TRUE,
linesep = "") %>%
cat(.,file= "cm_rf.tex")
dim(data)
table(data$ind2_cat)
data_manuf <- data %>% filter(ind2_cat == 56 | ind2_cat == 55)
data_serv <- data %>% filter(ind2_cat != 56 & ind2_cat != 55)
table(data_manuf$future_fast_growth)
table(data_serv$future_fast_growth)
set.seed(13505)
train_indices <- as.integer(createDataPartition(data_manuf$future_fast_growth, p = 0.8, list = FALSE))
data_manuf_train <- data_manuf[train_indices, ]
data_manuf_holdout <- data_manuf[-train_indices, ]
dim(data_manuf_train)
dim(data_manuf_holdout)
table(data_manuf$future_fast_growth_f)
table(data_manuf_train$future_fast_growth_f)
table(data_manuf_holdout$future_fast_growth_f)
rf_model_f_manuf <- train(
formula(paste0("future_fast_growth_f ~ ", paste0(rfvars , collapse = " + "))),
method = "ranger",
data = data_manuf_train,
tuneGrid = tune_grid,
trControl = train_control
)
data_manuf_train$rf_f_prediction_class <-  predict(rf_model_f_manuf,type = "raw")
data_manuf_holdout$rf_f_prediction_class <- predict(rf_model_f_manuf, newdata = data_manuf_holdout, type = "raw")
#We use predicted classes to calculate expected loss based on our loss fn
fp <- sum(data_manuf_holdout$rf_f_prediction_class == "fast_growth" & data_manuf_holdout$future_fast_growth_f == "no_fast_growth")
fn <- sum(data_manuf_holdout$rf_f_prediction_class == "no_fast_growth" & data_manuf_holdout$future_fast_growth_f == "fast_growth")
(fp*FP + fn*FN)/length(data_manuf_holdout$future_fast_growth)
set.seed(13505)
train_indices <- as.integer(createDataPartition(data_serv$future_fast_growth, p = 0.8, list = FALSE))
data_serv_train <- data_serv[train_indices, ]
data_serv_holdout <- data_serv[-train_indices, ]
dim(data_serv_train)
dim(data_serv_holdout)
table(data_serv$future_fast_growth_f)
table(data_serv_train$future_fast_growth_f)
table(data_serv_holdout$future_fast_growth_f)
rf_model_f_serv <- train(
formula(paste0("future_fast_growth_f ~ ", paste0(rfvars , collapse = " + "))),
method = "ranger",
data = data_serv_train,
tuneGrid = tune_grid,
trControl = train_control
)
data_serv_train$rf_f_prediction_class <-  predict(rf_model_f_serv,type = "raw")
data_serv_holdout$rf_f_prediction_class <- predict(rf_model_f_serv, newdata = data_serv_holdout, type = "raw")
#We use predicted classes to calculate expected loss based on our loss fn
fp <- sum(data_serv_holdout$rf_f_prediction_class == "fast_growth" & data_serv_holdout$future_fast_growth_f == "no_fast_growth")
fn <- sum(data_serv_holdout$rf_f_prediction_class == "no_fast_growth" & data_serv_holdout$future_fast_growth_f == "fast_growth")
(fp*FP + fn*FN)/length(data_serv_holdout$future_fast_growth)
expected_loss_holdout
expected_loss_holdout
expected_loss_holdout <- (holdout_treshold$fp*FP + holdout_treshold$fn*FN)/length(data_holdout$future_fast_growth)
expected_loss_holdout
expected_loss_holdout <- (holdout_treshold$fp*FP + holdout_treshold$fn*FN)/length(data_holdout$future_fast_growth)
expected_loss_holdout
# Get expected loss on holdout
holdout_treshold <- coords(roc_obj_holdout, x = best_logit_optimal_treshold, input= "threshold",
ret="all", transpose = FALSE)
expected_loss_holdout <- (holdout_treshold$fp*FP + holdout_treshold$fn*FN)/length(data_holdout$future_fast_growth)
expected_loss_holdout
# Introduce loss function
# relative cost of of a false negative classification (as compared with a false positive classification)
FP=1000
FN=5000
best_logit_with_loss <- logit_models[["X2"]]
best_logit_optimal_treshold <- best_tresholds[["X2"]]
logit_predicted_probabilities_holdout <- predict(best_logit_with_loss, newdata = data_holdout, type = "prob")
data_holdout[,"best_logit_with_loss_pred"] <- logit_predicted_probabilities_holdout[,"fast_growth"]
# ROC curve on holdout
roc_obj_holdout <- roc(data_holdout$future_fast_growth, data_holdout[, "best_logit_with_loss_pred", drop=TRUE])
# Get expected loss on holdout
holdout_treshold <- coords(roc_obj_holdout, x = best_logit_optimal_treshold, input= "threshold",
ret="all", transpose = FALSE)
expected_loss_holdout <- (holdout_treshold$fp*FP + holdout_treshold$fn*FN)/length(data_holdout$future_fast_growth)
expected_loss_holdout
dim(data)
